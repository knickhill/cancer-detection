{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get keras\n",
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import *\n",
    "from keras import Model, Sequential\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "y = np.load('Y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not standardize images\n",
    "X = np.load('X_train.npy')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0],X.shape[1],X.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "np.random.seed(111)\n",
    "\n",
    "#split to test, train and val\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "s_train = s[:8000]\n",
    "s_val = s[8000:9000]\n",
    "s_test =s[9000:X.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and val\n",
    "X_train = X[s_train]\n",
    "y_train = y[s_train]\n",
    "\n",
    "X_val = X[s_val]\n",
    "y_val = y[s_val]\n",
    "\n",
    "#generate testset\n",
    "X_test = X[s_test]\n",
    "y_test = y[s_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y in y_bin\n",
    "y_bin = np.zeros((y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y to y_bin\n",
    "#0 - normal 1 - pathological\n",
    "for i in range(y.shape[0]):\n",
    "    if all(y[i]==0):\n",
    "        y_bin[i] = 0\n",
    "    else:\n",
    "        y_bin[i] = 1\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split y into train and test\n",
    "y_bin_train = y_bin[s_train]\n",
    "y_bin_val = y_bin[s_val]\n",
    "y_bin_test = y_bin[s_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check y_bin traintest and val sets are balanced\n",
    "print(\"ratio of normal to total in train:\",len(np.where(y_bin_train==0)[0])/y_bin_train.shape[0])\n",
    "print(\"ratio of normal to total in val:\",len(np.where(y_bin_val==0)[0])/y_bin_val.shape[0])\n",
    "print(\"ratio of normal to total in test:\",len(np.where(y_bin_test==0)[0])/y_bin_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- They seem adequately balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing out alorithm with black and whites\n",
    "## creating dummy black and white images\n",
    "# X_train_ = np.zeros_like(X_train)\n",
    "# for i,y in enumerate(y_bin_train):\n",
    "#     X_train_[i] = np.ones((256, 256, 1))*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, classes = (256, 256, 1), 1\n",
    "input_tnsr = keras.layers.Input(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set learning rate for all models 0.0001 (showed to be the best rate)\n",
    "adam_customlr = keras.optimizers.Adam(lr=0.0001) #decrease lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Epoch number for all\n",
    "num_epoch=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "In the following we will compare three models: A simple model, resnet50, MobileNet and VGG16 as the literature suggests these perform best. We will do so by keeping the parameters constant to select the best performing architecture and then choose the winning model in terms of accuracy to perform fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple model; 6 layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "history_simple_model = model.fit(X_train, y_bin_train, epochs=num_epoch, batch_size=32, verbose=1,validation_data=(X_val,y_bin_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model - Visualize accuracy and loss of test and validation\n",
    "print(history_simple_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_simple_model.history['acc'])\n",
    "plt.plot(history_simple_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_simple_model.history['loss'])\n",
    "plt.plot(history_simple_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and loss on test set for baseline model\n",
    "model.evaluate(X_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the baseline\n",
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet-Model (50 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple resnet - no data augmentation or pretraining. \n",
    "input_tnsr = keras.layers.Input(shape)\n",
    "model_rsnt = ResNet50(include_top=False, weights = None, input_tensor = input_tnsr, classes = classes, pooling=None)\n",
    "rsnt_input_layer = model_rsnt.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_rsnt.layers[-1].output\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "cstm_resnet = Model(inputs=rsnt_input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit- same learning rate as simple model\n",
    "cstm_resnet.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_cstm_resnet = cstm_resnet.fit(X_train, y_bin_train, epochs=num_epoch, batch_size=32, verbose=1,validation_data=(X_val,y_bin_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy and loss on test set \n",
    "cstm_resnet.evaluate(X_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate plots\n",
    "#Baseline model\n",
    "# list all data in history\n",
    "print(history_cstm_resnet.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_cstm_resnet.history['acc'])\n",
    "plt.plot(history_cstm_resnet.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_cstm_resnet.history['loss'])\n",
    "plt.plot(history_cstm_resnet.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the cstm_resnet\n",
    "cstm_resnet.save('cstm_resnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MobileNet\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "mobnet = MobileNet(input_tensor=input_tnsr, include_top=False, weights=None, classes=classes, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobnet_input_layer = mobnet.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = mobnet.layers[-1].output\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(32, activation='relu')(x1)\n",
    "x1 = Dense(1, activation='sigmoid')(x1)\n",
    "\n",
    "cstm_mobnet = Model(inputs=mobnet_input_layer, outputs=x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_mobnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit- same learning rate as simple model;\n",
    "cstm_mobnet.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_cstm_mobnet = cstm_mobnet.fit(X_train, y_bin_train, epochs=num_epoch, batch_size=32, verbose=1,validation_data=(X_val,y_bin_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy and loss on test set \n",
    "cstm_mobnet.evaluate(X_test,y_bin_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate plots\n",
    "#Baseline model\n",
    "# list all data in history\n",
    "print(history_cstm_mobnet.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_cstm_mobnet.history['acc'])\n",
    "plt.plot(history_cstm_mobnet.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_cstm_mobnet.history['loss'])\n",
    "plt.plot(history_cstm_mobnet.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the cstm_resnet\n",
    "cstm_mobnet.save('cstm_mobnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out VGG16\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tnsr = keras.layers.Input(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_vgg = VGG16(include_top=False, weights = None,  input_tensor = input_tnsr, classes = classes, pooling=None)\n",
    "vgg_input_layer = model_vgg.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = model_vgg.layers[-1].output\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(32, activation='relu')(x2)\n",
    "x2 = Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "cstm_vgg = Model(inputs=vgg_input_layer, outputs=x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "cstm_vgg.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit- same learning rate as simple model; only change epochs to 15\n",
    "history_cstm_vgg = cstm_vgg.fit(X_train, y_bin_train, epochs=num_epoch, batch_size=32, verbose=1,validation_data=(X_val,y_bin_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate plots\n",
    "#Baseline model\n",
    "# list all data in history\n",
    "print(history_cstm_vgg.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_cstm_vgg.history['acc'])\n",
    "plt.plot(history_cstm_vgg.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_cstm_vgg.history['loss'])\n",
    "plt.plot(history_cstm_vgg.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy and loss on test set \n",
    "cstm_vgg.evaluate(X_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the cstm_resnet\n",
    "cstm_vgg.save('cstm_vgg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of comparison\n",
    "The best performing architecture seems to be the VGG16. We will proceed with it and try different kind of architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG with imagenet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = np.load('X_train.npy')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3ch= np.zeros((X_raw.shape[0],X_raw.shape[1],X_raw.shape[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying grayscale images across 3 channel for  using imagenet-trained weights \n",
    "for i in range(X_raw.shape[0]):\n",
    "    X_3ch[i] = np.stack((X_raw[i],)*3, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3c_train = X_3ch[s_train]\n",
    "X_3c_val = X_3ch[s_val]\n",
    "X_3c_test = X_3ch[s_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new shape and tensor\n",
    "shape_3c = (256, 256, 3)\n",
    "input_tnsr_3c = keras.layers.Input(shape_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change weights to imagenet\n",
    "model_vgg_weights = VGG16(include_top=False, weights = 'imagenet', input_tensor = input_tnsr_3c, classes = classes, pooling=None)\n",
    "vgg_im_input_layer = model_vgg_weights.input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = model_vgg_weights.layers[-1].output\n",
    "x3 = Flatten()(x3)\n",
    "x3 = Dense(32, activation='relu')(x3)\n",
    "x3 = Dense(1, activation='sigmoid')(x3)\n",
    "\n",
    "model_vgg_weights = Model(inputs=vgg_im_input_layer, outputs=x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg_weights.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit- same learning rate as simple model; only change epochs to 15\n",
    "model_vgg_weights.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cstm_vgg_weights = model_vgg_weights.fit(X_3c_train, y_bin_train, epochs=num_epoch, batch_size=32, verbose=1,validation_data=(X_3c_val,y_bin_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy and loss on test set \n",
    "model_vgg_weights.evaluate(X_3c_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate plots\n",
    "#Baseline model\n",
    "# list all data in history\n",
    "print(history_cstm_vgg_weights.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_cstm_vgg_weights.history['acc'])\n",
    "plt.plot(history_cstm_vgg_weights.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_cstm_vgg_weights.history['loss'])\n",
    "plt.plot(history_cstm_vgg_weights.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the cstm_resnet\n",
    "model_vgg_weights.save('cstm_vgg_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "  #  featurewise_center=True,\n",
    "  #  featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_aug = cstm_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_aug.compile(optimizer = adam_customlr, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "vgg16_aug_history = cstm_vgg.fit_generator(datagen.flow(X_train, y_bin_train, batch_size=32),\n",
    "                        steps_per_epoch=len(X_train) // 32, epochs=num_epoch, verbose=1,\n",
    "                                   validation_data=test_datagen.flow(X_val,y_bin_val,batch_size=32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate plots\n",
    "#Baseline model\n",
    "# list all data in history\n",
    "print(vgg16_aug_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(vgg16_aug_history.history['acc'])\n",
    "plt.plot(vgg16_aug_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(vgg16_aug_history.history['loss'])\n",
    "plt.plot(vgg16_aug_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_aug.evaluate(X_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save simple model as the cstm_resnet\n",
    "vgg16_aug.save('vgg16_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing ROC for different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC for simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC curves\n",
    "model = load_model('baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_bin_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
